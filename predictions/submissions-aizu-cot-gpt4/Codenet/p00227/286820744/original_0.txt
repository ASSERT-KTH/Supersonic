The optimization could be made in several ways:

1. Memory Optimization: Instead of using the `std::vector::push_back` function, which could potentially cause multiple reallocations if the number of elements exceeds the current capacity of the vector, we can use `std::vector::reserve` function to allocate memory once. We know the size of the vector in advance (`num`), so we can allocate the exact amount of memory we need.

2. Time Optimization: The `std::vector::at` function is safe because it throws an exception if the index is out of bounds, but it is slower than the `operator[]`. Since we are sure that we will not go out of bounds, we can use the `operator[]` to speed up the program.

3. Avoiding unnecessary computation: The check `(i + 1) % cap != 0` is used to skip every `cap`th element starting from the end. We can directly increment `i` by `cap` after adding `cap - 1` elements to the `sum` to avoid unnecessary computation.

Here's the optimized code:

```cpp
#include <algorithm>
#include <iostream>
#include <vector>

int main() {
  int num, cap, price;
  while (std::cin >> num >> cap) {
    if (num == 0 && cap == 0) {
      break;
    }
    std::vector<int> vegetables(num);
    for (int i = 0; i < num; ++i) {
      std::cin >> price;
      vegetables[i] = price;
    }
    std::sort(vegetables.begin(), vegetables.end(), std::greater<int>());
    
    int sum = 0;
    for (int i = 0; i < num; i += cap) {
      for (int j = i; j < std::min(i + cap - 1, num); ++j) {
        sum += vegetables[j];
      }
    }
    std::cout << sum << std::endl;
  }
}
```
Remember this optimization makes sense mainly for large inputs. For small inputs, the gain could be negligible.