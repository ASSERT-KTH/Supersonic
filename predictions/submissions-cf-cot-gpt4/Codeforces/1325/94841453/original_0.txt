Here is your optimized program. The original program uses a `set` to store unique elements. The `set` in C++ is typically implemented as a binary search tree. The time complexity for insertion in a `set` is O(log n). This is not efficient when the size of the input is large. 

A more efficient approach is to use an `unordered_set` instead of a `set`. The `unordered_set` in C++ is implemented as a hash table. The time complexity for insertion in an `unordered_set` is O(1) on average, which is more efficient than `set`.

Here is the optimized program:

```cpp
#include <bits/stdc++.h>
#define ll long long
using namespace std;
int main() {
  ll t;
  cin >> t;
  while (t--) {
    ll n, x;
    cin >> n;
    unordered_set<ll> a;
    while (n--) {
      cin >> x;
      a.insert(x);
    }
    cout << a.size() << endl;
  }
}
```

This program is optimized for running time. The memory usage optimization in this case is not possible without changing the basic logic of the program, as we still need to store all unique elements, regardless of whether we use `set` or `unordered_set`.