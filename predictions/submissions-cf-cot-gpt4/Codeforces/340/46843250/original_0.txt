There are several ways that we can optimize this code. Here are a few key steps:

1. **Removing unnecessary macros**: The macros at the beginning of the program are mostly unnecessary and some of them are not even used in the program (e.g., `debug(x)`, `Sort(x)`, `F`, `S`, `Mp`). Removing these will reduce clutter and memory usage. 

2. **Avoid Global Variables**: The `a` array and the `s` multiset are declared as global variables. This is not necessary and can lead to higher memory usage and potential issues with variable scope. These can be declared inside the `Main()` function instead.

3. **Avoid Using `std` Namespace**: Using the entire `std` namespace is generally not a good practice as it can lead to name clashes. Instead, you can specify exactly which elements you are using (e.g., `using std::cin; using std::cout;`).

4. **Avoid using `sync` macro**: Using the `sync` macro can cause slowdowns in some situations due to unnecessary synchronization. It's generally better to handle input/output manually.

5. **Using `ios_base::sync_with_stdio(false);` and `cin.tie(NULL);`**: This will make input and output more efficient.

6. **Avoid unnecessary function calls**: The `sz(s)` call is unnecessary and can be replaced with `s.size()`, which is more efficient.

7. **Avoid unnecessary while loops**: The `while (q--)` loop in the `main()` function is unnecessary and can be removed.

Here is the code after optimization:

```cpp
#include <iostream>
#include <vector>
#include <set>
#include <algorithm>
typedef long long ll;

const int MAXN = 1e5 + 300;

int main() {
  std::ios_base::sync_with_stdio(false);
  std::cin.tie(NULL);
  ll n;
  std::cin >> n;
  std::vector<ll> a(n);
  std::multiset<ll> s;

  for (int i = 0; i < n; i++)
    std::cin >> a[i];
  for (int i = 0; i < n; i++) {
    auto it = s.lower_bound(a[i]);
    if (it != s.end())
      s.erase(it);
    s.insert(a[i]);
  }
  std::cout << s.size();
  return 0;
}
```
The optimization is focused on reducing the memory usage and improving readability and best practices, but the algorithmic complexity remains the same.