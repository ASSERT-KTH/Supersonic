The optimizations I can suggest are:

1. **Array to Vector:** Instead of using an array, we can use a vector. The reason is that in C++, it's not recommended to use VLA (Variable Length Array) which is not a standard feature in C++. So, we can replace `int arr[n]` with `std::vector<int> arr(n)`. This will ensure that we use only the required amount of memory.

2. **Reduce Scope:** The variable `f` is only needed inside the second-to-last for loop, so we can reduce its scope by declaring it inside the loop. This is a good practice in C++, even though it doesn't provide a significant memory or performance improvement.

3. **Avoid Repeated Calculations:** In the second-to-last for loop, `lpf[arr[i]]` is calculated twice. To avoid this, we can store its value in the variable `f` and use it again. This can speed up the program as it avoids repeating the same calculation.

4. **Efficient Max Calculation:** Instead of using `maxi = max(maxi, (int)cont[i])` to calculate the maximum, we can use `if` condition. This is faster because the `max` function involves more operations than a simple `if` condition.

Here is the optimized code:

```cpp
#include <bits/stdc++.h>
using namespace std;
using ll = long long;
#define N 17000005
int lpf[N];
int cont[N];
void sieve() {
  for (int i = 2; i < N; i++) {
    if (lpf[i] == 0) {
      lpf[i] = i;
      for (ll j = 1LL * i * i; j < N; j += i) {
        if (lpf[j] == 0)
          lpf[j] = i;
      }
    }
  }
}
int main() {
  sieve();
  int n;
  cin >> n;
  vector<int> arr(n);
  int mcd = 0;
  for (int i = 0; i < n; i++) {
    cin >> arr[i];
    mcd = __gcd(mcd, arr[i]);
  }
  for (int i = 0; i < n; i++)
    arr[i] /= mcd;
  for (int i = 0; i < n; i++) {
    while (arr[i] > 1) {
      int f = lpf[arr[i]];
      cont[f]++;
      while (arr[i] % f == 0)
        arr[i] /= f;
    }
  }
  int maxi = 0;
  for (int i = 0; i < N; i++)
    if(cont[i] > maxi)
        maxi = cont[i];
  if (maxi == 0)
    cout << -1 << '\n';
  else
    cout << n - maxi << '\n';
  return 0;
}
```