The original program is already quite optimized. However, we can make a few small changes to improve its performance even further.

First, we can avoid unnecessary calls to the `set::insert` method by constructing the set directly from the vector. This reduces the time complexity from O(n log n) to O(n). 

Second, we can remove the call to `map::clear` and `set::clear` at the end of each test case. These calls are unnecessary because the map and set are reinitialized at the beginning of each test case, so clearing them at the end is a waste of time. 

Third, we can remove the `s` set entirely. It is used only to count the unique elements, but we can get this information directly from the map `m`.

Here is the optimized code:

```cpp
#include <bits/stdc++.h>
using namespace std;
#define f(i, a, b) for (int i = a; i < b; i++)
#define ll long long
#define endl '\n'
#define pb push_back
#define mp make_pair
#define vi vector<int>
#define deb(x) cout << #x << " " << x << endl;
#define ff first
#define ss second
#define mod 998244353
#define inf 4e18
#define all(v) v.begin(), v.end()
#define fast ios_base::sync_with_stdio(0); cin.tie(NULL); cout.tie(NULL);
const int N = 1e6 + 10;
const ll MOD = (ll)(1e9) + (ll)(7);
int main() {
  fast;
  int t;
  cin >> t;
  while (t--) {
    int n;
    cin >> n;
    vi v(n);
    f(i, 0, n) cin >> v[i];
    map<int, int> m;
    int M = -1;
    for (auto x : v){
      m[x]++;
      M = max(M, m[x]);
    }
    if (n >= 2 && m.size() == n) {
      cout << 1 << endl;
      continue;
    }
    if (m.size() > M) {
      cout << M << endl;
    } else if (m.size() == M) {
      cout << M - 1 << endl;
    } else {
      cout << m.size() << endl;
    }
  }
  return 0;
}
```

Note: In a real-world application, it would be advisable to avoid using `#include <bits/stdc++.h>`, because it includes more headers than necessary, which can significantly slow down compilation time. Instead, include only the headers that you actually need.