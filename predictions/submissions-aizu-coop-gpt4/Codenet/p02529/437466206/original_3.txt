The given C program reads two arrays S and T from the standard input and counts how many elements of T are also in S. The main performance issue of this program is that it checks for each of the n elements in S if it is present in the array T which has q elements. This algorithm is O(n*q), which means that the time it takes to run increases linearly with the size of both input arrays.

Here is the optimization strategy:

1. Data structure optimization: The current data structure is an array, which is not efficient for checking if an element is present. We can switch to a data structure such as a hash set or a binary tree that has an average time complexity of O(log n) or O(1) for search operations. The C++ Standard Template Library (STL) provides `unordered_set` which is a hash set implementation.

2. Redundant computations: In this case, the search operation in the second for-loop can be seen as a redundant computation since the same operation is repeated for each element in S. By changing the data structure, we can avoid this redundancy.

3. Compiler optimizations: While not directly related to the source code, enabling compiler optimizations can also improve the performance of the program. This can be done by using the `-O2` or `-O3` flags when compiling the program with GCC or Clang.

Here's how we can optimize the program:

```cpp
#include <stdio.h>
#include <unordered_set>

int main() {
  int i, n, q, t, C = 0, S[100], T[100];
  std::unordered_set<int> S_set;
  
  scanf("%d", &n);
  for (i = 0; i < n; i++) {
    scanf("%d", &S[i]);
    S_set.insert(S[i]);  // Insert the elements of S into the hash set
  }
  
  scanf("%d", &q);
  for (i = 0; i < q; i++) {
    scanf("%d", &T[i]);
  }

  for (i = 0; i < q; i++) {
    if (S_set.count(T[i])) {  // Check if T[i] is in the hash set
      C++;
    }
  }
  printf("%d\n", C);
  return 0;
}
```

This optimized program now has a time complexity of O(n + q), because the `unordered_set::count` function is generally O(1).

This optimization does come with a trade-off:

1. Memory usage: `unordered_set` uses more memory than a plain array since it needs to maintain additional data to support its hash table. However, given the relatively small size of the input (100 elements), this increase in memory usage should be negligible.